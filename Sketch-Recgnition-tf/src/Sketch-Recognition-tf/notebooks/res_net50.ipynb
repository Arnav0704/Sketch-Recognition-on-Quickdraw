{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f6f8db",
   "metadata": {},
   "source": [
    "# ResNet50 Model On QuickDraw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, callbacks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUM_CLASSES = 30\n",
    "SAMPLES_PER_CLASS = 5000\n",
    "IMG_SIZE = (28, 28)\n",
    "BATCH_SIZE = 64  # Reduced for 16GB RAM\n",
    "EPOCHS = 50\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading (from .npy files)\n",
    "def load_data(class_names, samples_per_class=5000):\n",
    "    X, y = [], []\n",
    "    for class_idx, name in enumerate(class_names):\n",
    "        data = np.load(f\"{name.lower()}.npy\")[:samples_per_class]\n",
    "        X.append(data)\n",
    "        y.append(np.full(len(data), class_idx))\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "# List of classes\n",
    "class_names = ['Airplane', 'Apple', 'Bicycle', 'Book', 'Car', 'Cat', 'Chair', 'Clock', 'Dog', 'Door', 'Eye', 'Fish', 'Flower', 'Fork', 'House', 'Key', 'Ladder', 'Moon', 'Mountain', 'Pizza', 'Rainbow', 'Shoe', 'Smiley Face', 'Star', 'Stop Sign', 'Sun', 'Table', 'Tennis Racquet', 'Tree', 'Wheel']\n",
    "X, y = load_data(class_names)\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Add channel dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test  = X_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocessing\n",
    "def preprocess(images):\n",
    "    # Rescale to [0,1]\n",
    "    return images / 255.0\n",
    "\n",
    "X_train = preprocess(X_train)\n",
    "X_test = preprocess(X_test)\n",
    "\n",
    "# 5. Data Augmentation\n",
    "data_augmentation = models.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_resnet(input_shape=(28,28,1), num_classes=30):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Convert grayscale to RGB by repeating channels\n",
    "    x = layers.Concatenate()([inputs]*3)\n",
    "    \n",
    "    # Modified ResNet50 for smaller images\n",
    "    base_model = applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None,  # No pretrained weights\n",
    "        input_tensor=x,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Custom classification head\n",
    "    x = layers.Dense(512, activation='relu')(base_model.output)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = build_resnet()\n",
    "model.summary()\n",
    "\n",
    "# 6. Compile with Mixed Precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 7. Callbacks\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_resnet.h5', save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# 8. Training with Data Generators\n",
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: data_augmentation(x, training=True)\n",
    ").flow(X_train, y_train, BATCH_SIZE)\n",
    "\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator().flow(X_test, y_test, BATCH_SIZE)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=len(X_test)//BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Evaluation\n",
    "model.load_weights('best_resnet.h5')\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
